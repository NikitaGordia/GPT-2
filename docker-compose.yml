services:
  # Base service with common configuration
  base: &base
    build:
      context: .
      dockerfile: trainer.Dockerfile
    container_name: gpt-trainer
    image: ${REGISTRY_URL}/gpt-trainer:${BUILD_TAG}
    volumes:
      - ./data:/trainer/data
      - ./models:/trainer/models
      - ./.dvc/cache:/trainer/.dvc/cache
    environment:
      - USE_DVC=1
      - PYTHONPATH=/trainer
      - PYTHONUNBUFFERED=1
    secrets:
      - aws_credentials
    
    command: ["python", "-m", "pytest", "tests"]

  # Service for training the model
  train:
    <<: *base
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: ["torchrun", "--nproc_per_node=1", "-m", "gpt.train"]

secrets:
  aws_credentials:
    file: ~/.aws/credentials